{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OGsiji/Transrisk-Innovation/blob/main/classification_of_time_series_with_lstm_rnn_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "fc0e8190e94168896963cc130335b87bff746508",
        "id": "hCbXKQ0n3zqc"
      },
      "source": [
        "# 0. Problem description\n",
        "--------------------------\n",
        "I've got this dataset of financial time series from my freinds at TenViz who's job is the magic of predicting stock market movements. The problem was formulated as follows:\n",
        "> ... to predict *target_class* based on values of *target_variable* & available features (dataset 'test_task_data.csv'). Before building a classifier, please pay attention to the nature of features and specific aspects of working with time series. Also, you can use *target_values* to derive useful information and additional features. As a train set use dataset from 2012-01-01 till 2016-12-31, as a test set used from 2017-01-02 till 2018-06-19. Finally, evaluate your model & provide analysis with short comments.\n",
        "> The results of the work should contain:\n",
        "> * Description of the steps of the solution of the task.\n",
        "> * Runnable implementation code in Python.\n",
        "> * PDF with the charts\n",
        "\n",
        "In this kernel/ notebook I review the raw time series data, apply necessery transformations and scaling, formulate a machine learning problem and build a classifier based on a stacked LSTM RNN.\n",
        "\n",
        "## Contents:\n",
        "1. [Load and Review Data](#1)\n",
        "2. [Feature Engineering](#2)\n",
        "3. [Data Pre-processing for LSTM Model](#3)\n",
        "4. [LSTM Model - Batch Training and Predictiction](#4)\n",
        "5. [APPENDIX - EDA for Individual Time Series](#5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2021-09-22T02:00:48.057482Z",
          "iopub.status.busy": "2021-09-22T02:00:48.056809Z",
          "iopub.status.idle": "2021-09-22T02:00:48.065765Z",
          "shell.execute_reply": "2021-09-22T02:00:48.064645Z",
          "shell.execute_reply.started": "2021-09-22T02:00:48.057175Z"
        },
        "id": "613IHQ273zqo"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt   # plotting\n",
        "import seaborn as sns   # plotting heatmap\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "45d3421670c4126bf734845e6d6f510cfd89706c",
        "id": "FsIje65e3zqr"
      },
      "source": [
        "# <a name=\"1\"></a> 1. Load and Review Data\n",
        "------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "8a5b2ee5686c4009fc70d1424739deb28024f34a",
        "execution": {
          "iopub.execute_input": "2021-09-22T02:00:48.068294Z",
          "iopub.status.busy": "2021-09-22T02:00:48.067879Z",
          "iopub.status.idle": "2021-09-22T02:00:48.104997Z",
          "shell.execute_reply": "2021-09-22T02:00:48.104335Z",
          "shell.execute_reply.started": "2021-09-22T02:00:48.068125Z"
        },
        "id": "E56mpLi23zqs"
      },
      "outputs": [],
      "source": [
        "# Import data, convert string dates to 'datetime64' and set the date column as index:\n",
        "df = pd.read_csv('../input/mainnnn/mainnn.csv',\n",
        "                 parse_dates=['DATE'],\n",
        "                 infer_datetime_format=True,\n",
        "                 index_col='DATE',\n",
        "                 thousands=',',\n",
        "                 decimal='.'\n",
        "                )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "2b243e2f4acb509e4154d0e4ae96201ff998b061",
        "execution": {
          "iopub.execute_input": "2021-09-22T02:00:48.106630Z",
          "iopub.status.busy": "2021-09-22T02:00:48.106196Z",
          "iopub.status.idle": "2021-09-22T02:00:48.112160Z",
          "shell.execute_reply": "2021-09-22T02:00:48.111223Z",
          "shell.execute_reply.started": "2021-09-22T02:00:48.106442Z"
        },
        "id": "_pmqDIiq3zqt"
      },
      "outputs": [],
      "source": [
        "#  Review the general info on data, paying attention to missing values and dtypes\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "7a7beb63ab9a69b377de13fe980055b61ae920df",
        "execution": {
          "iopub.execute_input": "2021-09-22T02:00:48.114095Z",
          "iopub.status.busy": "2021-09-22T02:00:48.113605Z",
          "iopub.status.idle": "2021-09-22T02:00:48.118841Z",
          "shell.execute_reply": "2021-09-22T02:00:48.117879Z",
          "shell.execute_reply.started": "2021-09-22T02:00:48.113853Z"
        },
        "id": "SCBqxVXn3zqu"
      },
      "outputs": [],
      "source": [
        "# Let's remove the empty column and look at some examples of data:\n",
        "#df = df.drop(columns='Unnamed: 17')\n",
        "#print(f'data shape = {df.shape}')\n",
        "#df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "bafb56da1194b944f6bf9147b8c1e3502c7f3f27",
        "execution": {
          "iopub.execute_input": "2021-09-22T02:00:48.120788Z",
          "iopub.status.busy": "2021-09-22T02:00:48.120215Z",
          "iopub.status.idle": "2021-09-22T02:00:48.127874Z",
          "shell.execute_reply": "2021-09-22T02:00:48.126734Z",
          "shell.execute_reply.started": "2021-09-22T02:00:48.120454Z"
        },
        "id": "QkmVxkMx3zqv"
      },
      "outputs": [],
      "source": [
        "# It appears that 'feature_5' has missing values up to 2012-10-18\n",
        "# let's fill them backwards\n",
        "df = df.fillna(method='bfill')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-09-22T02:00:48.129880Z",
          "iopub.status.busy": "2021-09-22T02:00:48.129416Z",
          "iopub.status.idle": "2021-09-22T02:00:48.140525Z",
          "shell.execute_reply": "2021-09-22T02:00:48.139726Z",
          "shell.execute_reply.started": "2021-09-22T02:00:48.129804Z"
        },
        "id": "Rhr6rH-a3zqx"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def clean_dataset(df):\n",
        "    assert isinstance(df, pd.DataFrame), \"df needs to be a pd.DataFrame\"\n",
        "    df.dropna(inplace=True)\n",
        "    indices_to_keep = ~df.isin([np.nan, np.inf, -np.inf]).any(1)\n",
        "    return df[indices_to_keep].astype(np.float64)\n",
        "\n",
        "\n",
        "df=clean_dataset(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "de0844e216b29256ddc07929a27d0f68e1912862",
        "execution": {
          "iopub.execute_input": "2021-09-22T02:00:48.142581Z",
          "iopub.status.busy": "2021-09-22T02:00:48.142351Z",
          "iopub.status.idle": "2021-09-22T02:00:48.148059Z",
          "shell.execute_reply": "2021-09-22T02:00:48.146919Z",
          "shell.execute_reply.started": "2021-09-22T02:00:48.142538Z"
        },
        "id": "mg-YO7eI3zqy"
      },
      "outputs": [],
      "source": [
        "# Basic statistics of the data:\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "d854a8ea49b73f44e67eb66f1c765b2142b85ebf",
        "execution": {
          "iopub.execute_input": "2021-09-22T02:00:48.150003Z",
          "iopub.status.busy": "2021-09-22T02:00:48.149464Z",
          "iopub.status.idle": "2021-09-22T02:00:51.773008Z",
          "shell.execute_reply": "2021-09-22T02:00:51.772023Z",
          "shell.execute_reply.started": "2021-09-22T02:00:48.149954Z"
        },
        "id": "oM1Whshz3zq0"
      },
      "outputs": [],
      "source": [
        "# Plot the time series\n",
        "plt.style.use('fivethirtyeight')\n",
        "df.plot(subplots=True,\n",
        "        layout=(6, 4),\n",
        "        figsize=(22,22),\n",
        "        fontsize=10, \n",
        "        linewidth=2,\n",
        "        sharex=False,\n",
        "        title='Visualization of the original Time Series')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "96fc893369d2c87a5585e4132c37d11d1888ea10",
        "execution": {
          "iopub.execute_input": "2021-09-22T02:00:51.774806Z",
          "iopub.status.busy": "2021-09-22T02:00:51.774327Z",
          "iopub.status.idle": "2021-09-22T02:00:53.685585Z",
          "shell.execute_reply": "2021-09-22T02:00:53.684745Z",
          "shell.execute_reply.started": "2021-09-22T02:00:51.774595Z"
        },
        "id": "QUBMBetd3zq1"
      },
      "outputs": [],
      "source": [
        "# Let's also draw a heatmap visualization of the correlation matrix\n",
        "corr_matrix = df.corr(method='spearman')\n",
        "f, ax = plt.subplots(figsize=(16,8))\n",
        "sns.heatmap(corr_matrix, annot=True, fmt='.2f', linewidth=0.4,\n",
        "            annot_kws={\"size\": 10}, cmap='coolwarm', ax=ax)\n",
        "plt.xticks(fontsize=10)\n",
        "plt.yticks(fontsize=10)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "fc0f05586212b8ad9afe10c34d337ec4d7d83810",
        "id": "GmXBOtKT3zq2"
      },
      "source": [
        "# <a name=\"2\"></a> 2. Feature Engineering\n",
        "-------\n",
        "### What do we have from the raw data review?\n",
        "* Exploratory Data Analysis of individual time series is visualized in the [APPENDIX](#index) below.\n",
        "* The raw data contain stochastic time series, including 'target_value'. Predicting/ making classification based on stochastic variable values may force the model to learn the 'persistence' mode (i.e. yhat(t+1) = y(t)), resulting in little predictive power. Defining the model to predict (make classification from) the difference in values between the time steps rather than value itself, is a stronger test of its predictive power. \n",
        "* The raw data are weakly correleted with the target_value and the target_class and among each other with rare exceptions. The predictive power could be in temporal effects. \n",
        "* The raw data are at different scales, therefore one more review after data transformation is needed to check if a standartization (for ~normal distribution of values) / normalization (for other distributions) is required to ensure efficient learning of NN models.\n",
        "\n",
        "Possible nature | TS_name | Description | Transformation | Rescaling after transformation\n",
        ":---: | :-- | :-- | :-- | :--\n",
        "class | target_class | binary (48%-1s, 52%-0s) | None | None\n",
        "stock index or indicator like RSI | [target_value](#target_value) | unimodal, bell-shaped, skewed to the right, stochastic trend with values in [48, 91], order +2 autocorr | pc_change or log diff | Standard\n",
        "stock index | [feature_1](#feature_1) | unimodal, bell-shaped, slightly skewed to the right, stochastic trend with values in [1432, 2539], order +2 autocorr | pc_change or log diff | Standard\n",
        "stock index | [feature_2](#feature_2) | bimodal, stochastic trend with values in [27, 126 ], order +2 autocorr | pc_change or log diff | Standard or MinMax\n",
        "stock index | [feature_3](#feature_3) | unimodal, strongly skewed to the right,  stochastic trend with values in [315, 830], order +2 autocorr  | pc_change or log diff | Standard or MinMax\n",
        "stock index | [feature_4](#feature_4) | unimodal, skewed to the right,  stochastic trend with values in [1, 6 ], order +2 autocorr | pc_change or log diff | Standard\n",
        "technical indicator | [feature_5](#feature_5) | unimodal, 5 descrete values  in [100+-0.00002], ordr +2 autocorr |  pc_change or log diff | Standard\n",
        "technical indicator | [feature_6](#feature_6) | unimodal, bell-shaped, ranging in [100+- 0.04], order +2 autocorr | pc_change or log diff | Standard\n",
        "technical indicator | [feature_7](#feature_7) | unimodal, skewed to the right, ranging in [100+-0.04], order -29/+31 autocorr  | pc_change or log diff | Standard\n",
        "technical indicator | [feature_8](#feature_8) | ranging around 100, occasional spikes in range [-340, +780] - [Q1'12, Q4'16], order 2 autocorr, negative values! | pc_change | Standard or MinMax\n",
        "technical indicator | [feature_9](#feature_9) | ranging around 100, occasional spikes in range [-3413, +2626] - [Q1'12, Q4'16], order 2 autocorr, negative values! | pc_change | Standard or MinMax\n",
        "technical indicator | [feature_10](#feature_10) | ranging around 100, occasional spikes in range [-2104, +2206] - [Q1'12, Q4'16], order 2 autocorr, negative values! | pc_change | Standard or MinMax\n",
        "technical indicator | [feature_11](#feature_11) | ranging around 100, occasional spikes in range [-1321, +1213 ] - [Q4'12-Q1'13], order 2 autocorr, negative values! | pc_change | Standard or MinMax\n",
        "technical indicator | [feature_12](#feature_12) | ranging around 100, occasional spikes in range [-2933, +2462 ] - [Q4'12-Q1'13], order 2 autocorr, negative values! | pc_change | Standard or MinMax\n",
        "technical indicator | [feature_13](#feature_13) | ranging around 100, occasional spikes in range [-3206, +2687 ] - [Q4'12-Q1'13], order 2 autocorr, negative values! | pc_change | Standard or MinMax\n",
        "technical indicator (oscillator) | [feature_14](#feature_14) | unimodal, skewed to the right, ranging in  [100+-0.02], autocorr +32 | pc_change or log diff | Standard\n",
        "technical indicator (oscillator) | [feature_15](#feature_15) | unimodal, bell-shaped, skewed to the left, ranging in [100+-0.02], autocorr -38 | pc_change or log diff | Standard\n",
        "technical indicator (oscillator) | [feature_16](#feature_16) | unimodal, bell-shaped, ranging in [100+-0.01], autocorr +14 | pc_change or log diff | Standard\n",
        "\n",
        "### Let's try a simple approach first and apply the pc_change to all *features* and *target_value* time series."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "f6cf1154f3c4bc16ea163cb04b3e82f000609f89",
        "execution": {
          "iopub.execute_input": "2021-09-22T02:00:53.687475Z",
          "iopub.status.busy": "2021-09-22T02:00:53.687043Z",
          "iopub.status.idle": "2021-09-22T02:00:53.691573Z",
          "shell.execute_reply": "2021-09-22T02:00:53.690751Z",
          "shell.execute_reply.started": "2021-09-22T02:00:53.687293Z"
        },
        "id": "-KCnPP2T3zq8"
      },
      "outputs": [],
      "source": [
        "# We want to keep original time series for the EDA in APPENDIX\n",
        "# So we apply the 'pc_change()' transformation to a copy of the original time series\n",
        "#df_transform = df[:,:'Target'].copy().pct_change(1)\n",
        "#df_transform.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-09-22T02:00:53.693481Z",
          "iopub.status.busy": "2021-09-22T02:00:53.692932Z",
          "iopub.status.idle": "2021-09-22T02:00:53.701798Z",
          "shell.execute_reply": "2021-09-22T02:00:53.700989Z",
          "shell.execute_reply.started": "2021-09-22T02:00:53.693427Z"
        },
        "id": "42S7gFPK3zq9"
      },
      "outputs": [],
      "source": [
        "#df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nft6hfdC3zq9"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "35b57d8915710fac9fee20e205d7e626a633949b",
        "execution": {
          "iopub.execute_input": "2021-09-22T02:00:53.703995Z",
          "iopub.status.busy": "2021-09-22T02:00:53.703392Z",
          "iopub.status.idle": "2021-09-22T02:00:53.711220Z",
          "shell.execute_reply": "2021-09-22T02:00:53.710323Z",
          "shell.execute_reply.started": "2021-09-22T02:00:53.703668Z"
        },
        "id": "bjbVaPNL3zq9"
      },
      "outputs": [],
      "source": [
        "# fill the 1st row with NA data\n",
        "#df_transform.fillna(method='bfill', inplace=True)\n",
        "#df_transform.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "e9f909592168dbb2444f09cd0ff9689d5355eb80",
        "execution": {
          "iopub.execute_input": "2021-09-22T02:00:53.714210Z",
          "iopub.status.busy": "2021-09-22T02:00:53.713867Z",
          "iopub.status.idle": "2021-09-22T02:00:57.597842Z",
          "shell.execute_reply": "2021-09-22T02:00:57.596904Z",
          "shell.execute_reply.started": "2021-09-22T02:00:53.714157Z"
        },
        "id": "chUi-Fbl3zq-"
      },
      "outputs": [],
      "source": [
        "# Plot the transformed time series\n",
        "plt.style.use('fivethirtyeight')\n",
        "df_transform.plot(subplots=True,\n",
        "                  layout=(6, 4),\n",
        "                  figsize=(24,24),\n",
        "                  fontsize=10, \n",
        "                  linewidth=2, \n",
        "                  title='Visualization of the transformed Features')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-09-22T02:00:57.599677Z",
          "iopub.status.busy": "2021-09-22T02:00:57.599147Z",
          "iopub.status.idle": "2021-09-22T02:00:57.653427Z",
          "shell.execute_reply": "2021-09-22T02:00:57.652414Z",
          "shell.execute_reply.started": "2021-09-22T02:00:57.599396Z"
        },
        "id": "sQdUnLj93zq_"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "b702785447d7d71a87daec25ba20133785573edd",
        "id": "bAOW78PG3zq_"
      },
      "source": [
        "### (!) We see that the mean and variance look almost constant except for a few outliers, but it is better to rescale the transformed time series either with StandardScaler or MinMaxScaler(-1, 1) for efficient model learning. The scalers are fit on the traning data and then applied to the test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "1a9b279fec35ae29d38a399e27d50cc4f3f56e2d",
        "execution": {
          "iopub.execute_input": "2021-09-22T02:00:57.655340Z",
          "iopub.status.busy": "2021-09-22T02:00:57.654799Z",
          "iopub.status.idle": "2021-09-22T02:00:57.671334Z",
          "shell.execute_reply": "2021-09-22T02:00:57.670246Z",
          "shell.execute_reply.started": "2021-09-22T02:00:57.655061Z"
        },
        "id": "vqX5xARf3zq_"
      },
      "outputs": [],
      "source": [
        "# Split train and test data  \n",
        "train_features = df.loc['2013-11-03':'2017-03-07']  \n",
        "train_labels = df.loc['2013-11-03':'2017-03-07', 'Target']\n",
        "\n",
        "test_features = df.loc['2018-05-25':'2018-12-11']\n",
        "test_labels = df.loc['2018-05-25':'2018-12-11', 'Target']\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# I want to use a T-days window of input data for predicting target_class\n",
        "# It means I need to prepend (T-1) last train records to the 1st test window\n",
        "T = 1 # my choice of the timesteps window\n",
        "\n",
        "prepend_features = train_features.iloc[-(T-1):]\n",
        "test_features = pd.concat([prepend_features, test_features], axis=0)\n",
        "\n",
        "train_features.shape, train_labels.shape, test_features.shape, test_labels.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1YvpGcMq3zrA"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "3a39792e3ae8bb0990fc76f3aa556fee383350f8",
        "execution": {
          "iopub.execute_input": "2021-09-22T02:00:57.673229Z",
          "iopub.status.busy": "2021-09-22T02:00:57.672705Z",
          "iopub.status.idle": "2021-09-22T02:00:57.683343Z",
          "shell.execute_reply": "2021-09-22T02:00:57.682285Z",
          "shell.execute_reply.started": "2021-09-22T02:00:57.672961Z"
        },
        "id": "ehqJocqB3zrA"
      },
      "outputs": [],
      "source": [
        "# Rescale the features\n",
        "from sklearn.preprocessing import StandardScaler  # MinMaxScaler\n",
        "\n",
        "scaler = StandardScaler()  # MinMaxScaler(feature_range=(-1,1))\n",
        "scaled_train_features = pd.DataFrame(scaler.fit_transform(train_features.values),\n",
        "                                     index=train_features.index,\n",
        "                                     columns=train_features.columns)\n",
        "# The Scaler is fit on the training set and then applied to the test set\n",
        "scaled_test_features = pd.DataFrame(scaler.transform(test_features.values),\n",
        "                                    index=test_features.index,\n",
        "                                    columns=test_features.columns)\n",
        "\n",
        "scaled_train_features.shape, scaled_test_features.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eqRbmbjh3zrB"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1WNpsHPU3zrB"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "887f12bb271f39f55dc2dcc2a8e19630b4b0af73",
        "execution": {
          "iopub.execute_input": "2021-09-22T02:00:57.685914Z",
          "iopub.status.busy": "2021-09-22T02:00:57.685216Z",
          "iopub.status.idle": "2021-09-22T02:01:01.657748Z",
          "shell.execute_reply": "2021-09-22T02:01:01.656827Z",
          "shell.execute_reply.started": "2021-09-22T02:00:57.685534Z"
        },
        "id": "OmBBmzQY3zrB"
      },
      "outputs": [],
      "source": [
        "# Plot the rescaled_train_features\n",
        "plt.style.use('fivethirtyeight')\n",
        "scaled_train_features.plot(subplots=True,\n",
        "                           layout=(6, 4),\n",
        "                           figsize=(24,24),\n",
        "                           fontsize=10, \n",
        "                           linewidth=2, \n",
        "                           title='Visualization of the scaled Train Features')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "f0375b7b6134ae049724f39f8ab4058d1a218087",
        "id": "t7nNYD2j3zrC"
      },
      "source": [
        ">  ## An alternative simplified transformation of the time-series (just to keep in mind): \n",
        "> Normalize sequences X = X/X_0 - 1, where X_0 is 1st example in the series:\n",
        "> * X_0_train, X_0_test = X_train[ : , 0], X_test[ : , 0]\n",
        "> * X_train = X_train/X_0_train[ : , None, :] - 1\n",
        "> * X_test = X_test/X_0_test[ : , None, :] - 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "9dff6ad61330a9867907e10857753798781b7484",
        "id": "YAikHvlf3zrC"
      },
      "source": [
        "# <a name=\"3\"></a> 3. Data Pre-processing for LSTM Model\n",
        "------------------------------------\n",
        "Input data for the Keras LSTM layer has 3 dimensions: (M, T, N), where \n",
        "* M - number of examples (2D: sequences of timesteps x features), \n",
        "* T - sequence length (timesteps) and \n",
        "* N - number of features (input_dim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "6ba7ead8825e60269e77e1bd873f2730a3269af7",
        "execution": {
          "iopub.execute_input": "2021-09-22T02:01:01.659584Z",
          "iopub.status.busy": "2021-09-22T02:01:01.659123Z",
          "iopub.status.idle": "2021-09-22T02:01:01.694256Z",
          "shell.execute_reply": "2021-09-22T02:01:01.693304Z",
          "shell.execute_reply.started": "2021-09-22T02:01:01.659388Z"
        },
        "id": "a89ENQmM3zrC"
      },
      "outputs": [],
      "source": [
        "# Create sequences of T timesteps\n",
        "\n",
        "X_train, y_train = [], []\n",
        "for i in range(train_labels.shape[0] - (T-1)):\n",
        "    X_train.append(scaled_train_features.iloc[i:i+T].values)\n",
        "    y_train.append(train_labels.iloc[i + (T-1)])\n",
        "X_train, y_train = np.array(X_train), np.array(y_train).reshape(-1,1)\n",
        "print(f'Train data dimensions: {X_train.shape}, {y_train.shape}')\n",
        "\n",
        "X_test, y_test = [], []\n",
        "for i in range(test_labels.shape[0]):\n",
        "    X_test.append(scaled_test_features.iloc[i:i+T].values)\n",
        "    y_test.append(test_labels.iloc[i])\n",
        "X_test, y_test = np.array(X_test), np.array(y_test).reshape(-1,1)  \n",
        "\n",
        "print(f'Test data dimensions: {X_test.shape}, {y_test.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y5xbOqid3zrD"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-09-22T02:01:01.696114Z",
          "iopub.status.busy": "2021-09-22T02:01:01.695487Z",
          "iopub.status.idle": "2021-09-22T02:01:01.699657Z",
          "shell.execute_reply": "2021-09-22T02:01:01.698961Z",
          "shell.execute_reply.started": "2021-09-22T02:01:01.695943Z"
        },
        "id": "HB6ApVMe3zrD"
      },
      "outputs": [],
      "source": [
        "#train_labels.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-09-22T02:01:01.701444Z",
          "iopub.status.busy": "2021-09-22T02:01:01.700975Z",
          "iopub.status.idle": "2021-09-22T02:01:01.708847Z",
          "shell.execute_reply": "2021-09-22T02:01:01.707877Z",
          "shell.execute_reply.started": "2021-09-22T02:01:01.701398Z"
        },
        "id": "UkCuut0g3zrD"
      },
      "outputs": [],
      "source": [
        "#import numpy as np\n",
        "#X_train = np.reshape(train_labels, (train_labels.shape[0], 1, train_labels.shape[1]))\n",
        "#X_test = np.reshape(train_labels, (train_labels.shape[0], 1, train_labels.shape[1]))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "dff08271d9278bf94b5a04885eb2b7acc2de8d15",
        "id": "ZjOTF_le3zrE"
      },
      "source": [
        "# <a name=\"4\"></a> 4. LSTM Model - Batch Training and Predictiction\n",
        "-------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "0788265ad4e08968109b8d22f4cb0e7ef374e6eb",
        "execution": {
          "iopub.execute_input": "2021-09-22T02:01:01.710667Z",
          "iopub.status.busy": "2021-09-22T02:01:01.710452Z",
          "iopub.status.idle": "2021-09-22T02:01:01.717610Z",
          "shell.execute_reply": "2021-09-22T02:01:01.716617Z",
          "shell.execute_reply.started": "2021-09-22T02:01:01.710628Z"
        },
        "id": "r_Gs89eh3zrE"
      },
      "outputs": [],
      "source": [
        "# Import Keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, BatchNormalization\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from keras.regularizers import l2\n",
        "from time import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "0990b2e8b73d3b9844b052c48341975d487fd6ec",
        "execution": {
          "iopub.execute_input": "2021-09-22T02:01:01.719935Z",
          "iopub.status.busy": "2021-09-22T02:01:01.719384Z",
          "iopub.status.idle": "2021-09-22T02:01:12.480112Z",
          "shell.execute_reply": "2021-09-22T02:01:12.479209Z",
          "shell.execute_reply.started": "2021-09-22T02:01:01.719758Z"
        },
        "id": "KMCHdnmC3zrE"
      },
      "outputs": [],
      "source": [
        "# Let's make a list of CONSTANTS for modelling:\n",
        "LAYERS = [8, 8, 8, 1]                # number of units in hidden and output layers\n",
        "M_TRAIN = X_train.shape[0]           # number of training examples (2D)\n",
        "M_TEST = X_test.shape[0]             # number of test examples (2D),full=X_test.shape[0]\n",
        "N = X_train.shape[2]                 # number of features\n",
        "BATCH = M_TRAIN                          # batch size\n",
        "EPOCH = 50                           # number of epochs\n",
        "LR = 5e-2                            # learning rate of the gradient descent\n",
        "LAMBD = 3e-2                         # lambda in L2 regularizaion\n",
        "DP = 0.0                             # dropout rate\n",
        "RDP = 0.0                            # recurrent dropout rate\n",
        "print(f'layers={LAYERS}, train_examples={M_TRAIN}, test_examples={M_TEST}')\n",
        "print(f'batch = {BATCH}, timesteps = {T}, features = {N}, epochs = {EPOCH}')\n",
        "print(f'lr = {LR}, lambda = {LAMBD}, dropout = {DP}, recurr_dropout = {RDP}')\n",
        "\n",
        "# Build the Model\n",
        "model = Sequential()\n",
        "model.add(LSTM(input_shape=(T, N), units=LAYERS[0],\n",
        "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
        "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
        "               dropout=DP, recurrent_dropout=RDP,\n",
        "               return_sequences=True, return_state=False,\n",
        "               stateful=False, unroll=False\n",
        "              ))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LSTM(units=LAYERS[1],\n",
        "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
        "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
        "               dropout=DP, recurrent_dropout=RDP,\n",
        "               return_sequences=True, return_state=False,\n",
        "               stateful=False, unroll=False\n",
        "              ))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LSTM(units=LAYERS[2],\n",
        "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
        "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
        "               dropout=DP, recurrent_dropout=RDP,\n",
        "               return_sequences=False, return_state=False,\n",
        "               stateful=False, unroll=False\n",
        "              ))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(units=LAYERS[3], activation='sigmoid'))\n",
        "\n",
        "# Compile the model with Adam optimizer\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              metrics=['accuracy'],\n",
        "              optimizer=Adam(lr=LR))\n",
        "print(model.summary())\n",
        "\n",
        "# Define a learning rate decay method:\n",
        "lr_decay = ReduceLROnPlateau(monitor='loss', \n",
        "                             patience=1, verbose=0, \n",
        "                             factor=0.5, min_lr=1e-8)\n",
        "# Define Early Stopping:\n",
        "early_stop = EarlyStopping(monitor='val_acc', min_delta=0, \n",
        "                           patience=30, verbose=1, mode='auto',\n",
        "                           baseline=0, restore_best_weights=True)\n",
        "# Train the model. \n",
        "# The dataset is small for NN - let's use test_data for validation\n",
        "start = time()\n",
        "History = model.fit(X_train, y_train,\n",
        "                    epochs=EPOCH,\n",
        "                    batch_size=BATCH,\n",
        "                    validation_split=0.0,\n",
        "                    validation_data=(X_test[:M_TEST], y_test[:M_TEST]),\n",
        "                    shuffle=True,verbose=0,\n",
        "                    callbacks=[lr_decay, early_stop])\n",
        "print('-'*65)\n",
        "print(f'Training was completed in {time() - start:.2f} secs')\n",
        "print('-'*65)\n",
        "# Evaluate the model:\n",
        "train_loss, train_acc = model.evaluate(X_train, y_train,\n",
        "                                       batch_size=M_TRAIN, verbose=0)\n",
        "test_loss, test_acc = model.evaluate(X_test[:M_TEST], y_test[:M_TEST],\n",
        "                                     batch_size=M_TEST, verbose=0)\n",
        "print('-'*65)\n",
        "print(f'train accuracy = {round(train_acc * 100, 4)}%')\n",
        "print(f'test accuracy = {round(test_acc * 100, 4)}%')\n",
        "print(f'test error = {round((1 - test_acc) * M_TEST)} out of {M_TEST} examples')\n",
        "\n",
        "# Plot the loss and accuracy curves over epochs:\n",
        "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(18,6))\n",
        "axs[0].plot(History.history['loss'], color='b', label='Training loss')\n",
        "axs[0].plot(History.history['val_loss'], color='r', label='Validation loss')\n",
        "axs[0].set_title(\"Loss curves\")\n",
        "axs[0].legend(loc='best', shadow=True)\n",
        "axs[1].plot(History.history['acc'], color='b', label='Training accuracy')\n",
        "axs[1].plot(History.history['val_acc'], color='r', label='Validation accuracy')\n",
        "axs[1].set_title(\"Accuracy curves\")\n",
        "axs[1].legend(loc='best', shadow=True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "ce50093c5976543a7d532ee07fdb7c19025cdbdb",
        "execution": {
          "iopub.execute_input": "2021-09-22T02:01:12.483200Z",
          "iopub.status.busy": "2021-09-22T02:01:12.482982Z",
          "iopub.status.idle": "2021-09-22T02:01:13.463748Z",
          "shell.execute_reply": "2021-09-22T02:01:13.462935Z",
          "shell.execute_reply.started": "2021-09-22T02:01:12.483159Z"
        },
        "id": "xpCSMXie3zrF"
      },
      "outputs": [],
      "source": [
        "y_hat = model.predict_classes(X_test, batch_size=M_TEST, verbose=1)\n",
        "#score = sum(y_hat == y_test) / len(y_test)\n",
        "#print(f'Prediction accuracy = {score*100}%')\n",
        "index = pd.date_range(start='2017-01-02', end='2018-06-19', freq='B')\n",
        "for i in range(y_hat.shape[0]):\n",
        "    print(index[i], y_hat[i], y_test[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "cef852352c3adb9d06733536bd3dab23b4a3fb38",
        "id": "MrW4jWgH3zrG"
      },
      "source": [
        "# <a name=\"5\"></a> 5. APPENDIX - Exploratory Data Analysis for Individual Time Series\n",
        "### <a name=\"index\"></a> INDEX:\n",
        "\n",
        "Reference | Reference | Reference\n",
        ":-- | :-- | :--\n",
        "[EDA Function](#eda_function) | [A-5. feature_5](#feature_5) | [A-11. feature_11](#feature_11) \n",
        "[A-0. target_value](#target_value) | [A-6. feature_6](#feature_6)  | [A-12. feature_12](#feature_12) \n",
        "[A-1. feature_1](#feature_1) | [A-7. feature_7](#feature_7) | [A-13. feature_13](#feature_13) \n",
        "[A-2. feature_2](#feature_2) | [A-8. feature_8](#feature_8) | [A-14. feature_14](#feature_14) \n",
        "[A-3. feature_3](#feature_3) | [A-9. feature_9](#feature_9) | [A-15. feature_15](#feature_15) \n",
        "[A-4. feature_4](#feature_4) | [A-10. feature_10](#feature_10) | [A-16. feature_16](#feature_16) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "7da4120745595001cbf94f314dab2829b11298b2",
        "id": "iGQQRMyh3zrG"
      },
      "source": [
        "<h1 id=\"eda_function\"> EDA Function </h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "b765c8b9cf4241d7ebd0f2aa675b68e162d12d55",
        "execution": {
          "iopub.execute_input": "2021-09-22T02:03:21.380165Z",
          "iopub.status.busy": "2021-09-22T02:03:21.379857Z",
          "iopub.status.idle": "2021-09-22T02:03:21.393498Z",
          "shell.execute_reply": "2021-09-22T02:03:21.392707Z",
          "shell.execute_reply.started": "2021-09-22T02:03:21.380112Z"
        },
        "id": "1NlwvweL3zrG",
        "outputId": "0122622e-153e-47d6-f382-1eb7f9fde280",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ]
        }
      ],
      "source": [
        "# Let's define a EDA function for repeated calls on individual time series:\n",
        "\n",
        "import statsmodels.api as sm  # seasonal trend decomposition\n",
        "from statsmodels.graphics import tsaplots   # autocorrelation\n",
        "\n",
        "def eda(df_name, ts_name, decomp_model='additive'):\n",
        "    \"\"\" \n",
        "    Inputs: df_name - name of the dataframe\n",
        "            ts_name - name of the time series in the dataframe\n",
        "            decomp_model - 'additive'/'multiplicative'\n",
        "    Outputs: EDA statistics and plots for individual time series in df_name\n",
        "    \"\"\"\n",
        "    # Statistics\n",
        "    print(f'Statistic of {ts_name} time series')\n",
        "    print(df_name[ts_name].describe())\n",
        "    \n",
        "    # Plotting\n",
        "    fig, axs = plt.subplots(nrows=4, ncols=2, figsize=(24,24))\n",
        "    fig.suptitle(f'Visualization of the \"{ts_name}\" time series', fontsize=24)\n",
        "        \n",
        "    # Observed values of the time series against target_class values\n",
        "    df_name[ts_name].plot(ylim=[df_name[ts_name].min(), df_name[ts_name].max()],\n",
        "                          linewidth=2, ax=axs[0,0])\n",
        "    axs[0,0].set_title('Observed values (red/green where target_class=0/1)')\n",
        "    axs[0,0].set_xlabel('')\n",
        "    axs[0,0].fill_between(df_name.index, df_name[ts_name], \n",
        "                          where=(df_name.Target==0),\n",
        "                          facecolor='red', alpha=0.5)\n",
        "    axs[0,0].fill_between(df_name.index, df_name[ts_name], \n",
        "                          where=(df_name.Target==1),\n",
        "                          facecolor='green', alpha=0.5)\n",
        "    axs[0,0].axvline('2017-01-01', color='red', linestyle='dashed')\n",
        "    \n",
        "    # Seasonality, trend and noise in time series data\n",
        "    decomp = sm.tsa.seasonal_decompose(df_name[ts_name],\n",
        "                                       model=decomp_model)\n",
        "    decomp.trend.plot(linewidth=2, ax=axs[0,1])\n",
        "    axs[0,1].set_title('Trend values')\n",
        "    axs[0,1].set_xlabel('')\n",
        "    decomp.seasonal.plot(linewidth=2, ax=axs[1,0])\n",
        "    axs[1,0].set_title('Seasonal values')\n",
        "    axs[1,0].set_xlabel('')\n",
        "    decomp.resid.plot(linewidth=2, ax=axs[1,1])\n",
        "    axs[1,1].set_title('Residual values')\n",
        "    axs[1,1].set_xlabel('')\n",
        "    \n",
        "    # Distribution of values of time series\n",
        "    df_name[ts_name].plot.hist(bins=30, ax=axs[2,0])\n",
        "    axs[2, 0].set_title('Histogram')\n",
        "    df_name[[ts_name]].boxplot(ax=axs[2,1])\n",
        "    axs[2, 1].set_title('Boxplot')\n",
        "        \n",
        "    # Autocorrelation of time series\n",
        "    tsaplots.plot_acf(df_name[ts_name], lags=40, ax=axs[3,0])\n",
        "    tsaplots.plot_pacf(df_name[ts_name], lags=40, ax=axs[3,1])\n",
        "    \n",
        "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "c98c398f139a1b45621cf75eb0c18a1a2604d40d",
        "id": "UFdgiRHU3zrH"
      },
      "source": [
        "# <a name=\"target_value\"></a> A-0. target_value \n",
        "[Back to INDEX](#index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "170bc7b1b98f15adb73d07b38fed4551c5d834a7",
        "execution": {
          "iopub.execute_input": "2021-09-22T02:03:26.227057Z",
          "iopub.status.busy": "2021-09-22T02:03:26.226724Z",
          "iopub.status.idle": "2021-09-22T02:03:27.946985Z",
          "shell.execute_reply": "2021-09-22T02:03:27.945706Z",
          "shell.execute_reply.started": "2021-09-22T02:03:26.226989Z"
        },
        "id": "Xx740gXq3zrI"
      },
      "outputs": [],
      "source": [
        "# Call EDA function to explore the time series\n",
        "eda(df, 'Turns', 'multiplicative')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "6962ed9b7d44a8ca6e0b72a752ebc24830612485",
        "id": "M58aAYLQ3zrI"
      },
      "source": [
        "\n",
        "### Conclusion: \n",
        "* **target_value** is unimodal bell-shaped (slightly skewed to the right); \n",
        "* decomposed into trend and stochastic noise;\n",
        "* percentage change is likely to have stationarity property\n",
        "* alternative - log transformation of the variable\n",
        "* it is possible to apply z-score standartization (sklearn StandardScaler)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "991417dd015438785d1762eb4ce85c0b3d508ad4",
        "id": "uih3p7Wb3zrI"
      },
      "source": [
        "# <a name=\"feature_1\"></a> A-1. feature_1\n",
        "[Back to INDEX](#index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "15561bee4c99170e0fe5135f570b37fd4ac53b30",
        "execution": {
          "iopub.status.busy": "2021-09-22T02:01:15.534313Z",
          "iopub.status.idle": "2021-09-22T02:01:15.536554Z"
        },
        "id": "5TOb5V3k3zrI"
      },
      "outputs": [],
      "source": [
        "# Call EDA function to explore the time series\n",
        "eda(df, 'feature_1', 'multiplicative')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "d1255f81bfb8803bcfe345c614dca55ef98b2e1c",
        "id": "Jtz6c84k3zrJ"
      },
      "source": [
        "# <a name=\"feature_2\"></a> A-2. feature_2\n",
        "[Back to INDEX](#index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "36fff5951336fc74bcbee4d84429caca89833002",
        "execution": {
          "iopub.status.busy": "2021-09-22T02:01:15.538946Z",
          "iopub.status.idle": "2021-09-22T02:01:15.541104Z"
        },
        "id": "vhvLWnc83zrJ"
      },
      "outputs": [],
      "source": [
        "# Call EDA function to explore the time series\n",
        "eda(df, 'feature_2', 'multiplicative')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "3507bbcbdb5c4ee58d8471ca22c9b99a78bb438b",
        "id": "381igBe63zrJ"
      },
      "source": [
        "# <a name=\"feature_3\"></a> A-3. feature_3\n",
        "[Back to INDEX](#index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "734069a7047b26f0d481e82115ee2c7b2f93f799",
        "execution": {
          "iopub.status.busy": "2021-09-22T02:01:15.543423Z",
          "iopub.status.idle": "2021-09-22T02:01:15.544080Z"
        },
        "id": "Ii2ph7EA3zrJ"
      },
      "outputs": [],
      "source": [
        "# Call EDA function to explore the time series\n",
        "eda(df, 'feature_3', 'multiplicative')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "04c27af5caee542668e45b1906ffba1b046df5c5",
        "id": "yCr7Lpy43zrK"
      },
      "source": [
        "# <a name=\"feature_4\"></a> A-4. feature_4\n",
        "[Back to INDEX](#index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "2ffc9d3403d8bd610882331606606e1dade0b7b3",
        "execution": {
          "iopub.status.busy": "2021-09-22T02:01:15.547848Z",
          "iopub.status.idle": "2021-09-22T02:01:15.548510Z"
        },
        "id": "5pQEaizo3zrK"
      },
      "outputs": [],
      "source": [
        "# Call EDA function to explore the time series\n",
        "eda(df, 'feature_4', 'multiplicative')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "44d2fbfe2795559eb3a4c388b9813f89587473da",
        "id": "xjQMRUot3zrK"
      },
      "source": [
        "# <a name=\"feature_5\"></a> A-5. feature_5\n",
        "[Back to INDEX](#index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "ee21565a242867ebdca368dbd25eb6c548a290ce",
        "execution": {
          "iopub.status.busy": "2021-09-22T02:01:15.549284Z",
          "iopub.status.idle": "2021-09-22T02:01:15.549914Z"
        },
        "id": "yTBk47C-3zrK"
      },
      "outputs": [],
      "source": [
        "# Call EDA function to explore the time series\n",
        "eda(df, 'feature_5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "10fa899eaae2872390b3d12392193f5b1bf24cc4",
        "id": "OYuDFxH_3zrL"
      },
      "source": [
        "# <a name=\"feature_6\"></a> A-6. feature_6\n",
        "[Back to INDEX](#index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "02d0057fbf309eddb7d96a4229245be531a96988",
        "execution": {
          "iopub.status.busy": "2021-09-22T02:01:15.550676Z",
          "iopub.status.idle": "2021-09-22T02:01:15.551311Z"
        },
        "id": "3aXNOvbq3zrL"
      },
      "outputs": [],
      "source": [
        "# Call EDA function to explore the time series\n",
        "eda(df, 'feature_6')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "f44270c90f0eae7a860e28886ca183f894aacea6",
        "id": "XGypiJNw3zrL"
      },
      "source": [
        "# <a name=\"feature_7\"></a> A-7. feature_7\n",
        "[Back to INDEX](#index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "d71df21ef029836c55031266f5631dcc51a8de26",
        "execution": {
          "iopub.status.busy": "2021-09-22T02:01:15.558315Z",
          "iopub.status.idle": "2021-09-22T02:01:15.558995Z"
        },
        "id": "l-DrB1dg3zrL"
      },
      "outputs": [],
      "source": [
        "# Call EDA function to explore the time series\n",
        "eda(df, 'feature_7')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "6f96d58abb258f34fd23009c9f018ecf8f519210",
        "id": "N1lIOwUw3zrM"
      },
      "source": [
        "# <a name=\"feature_8\"></a> A-8. feature_8\n",
        "[Back to INDEX](#index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "b49b63a91cd05bbf3497ee9b7d81a67a4e99db41",
        "execution": {
          "iopub.status.busy": "2021-09-22T02:01:15.559759Z",
          "iopub.status.idle": "2021-09-22T02:01:15.560392Z"
        },
        "id": "zuQzaSkf3zrM"
      },
      "outputs": [],
      "source": [
        "# Call EDA function to explore the time series\n",
        "eda(df, 'feature_8')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "30c3b07d7a156043c51dc4c58bc657d7dc6a276a",
        "id": "H9zvaTrc3zrM"
      },
      "source": [
        "# <a name=\"feature_9\"></a> A-9. feature_9\n",
        "[Back to INDEX](#index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "acb13cef0fd3ce58f70b3448fa704de8d2be1745",
        "execution": {
          "iopub.status.busy": "2021-09-22T02:01:15.561171Z",
          "iopub.status.idle": "2021-09-22T02:01:15.561762Z"
        },
        "id": "z99EQxCP3zrN"
      },
      "outputs": [],
      "source": [
        "# Call EDA function to explore the time series\n",
        "eda(df, 'feature_9')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "274fa7de253f79f7fe42b967a5936eccf4889283",
        "id": "OFRmxeli3zrN"
      },
      "source": [
        "# <a name=\"feature_10\"></a> A-10. feature_10\n",
        "[Back to INDEX](#index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "940690191c3f33deac278e3129903b30853a5cb7",
        "execution": {
          "iopub.status.busy": "2021-09-22T02:01:15.562508Z",
          "iopub.status.idle": "2021-09-22T02:01:15.563128Z"
        },
        "id": "xiQK8W393zrN"
      },
      "outputs": [],
      "source": [
        "# Call EDA function to explore the time series\n",
        "eda(df, 'feature_10')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "56bbbbc6659443b79ae177adf3a1f708128bcedc",
        "id": "goUvXWiM3zrO"
      },
      "source": [
        "# <a name=\"feature_11\"></a> A-11. feature_11\n",
        "[Back to INDEX](#index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "05deedd97616e1c605584c748e0657c5899244af",
        "execution": {
          "iopub.status.busy": "2021-09-22T02:01:15.563894Z",
          "iopub.status.idle": "2021-09-22T02:01:15.564499Z"
        },
        "id": "yaPmTILQ3zrO"
      },
      "outputs": [],
      "source": [
        "# Call EDA function to explore the time series\n",
        "eda(df, 'feature_11')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "8fd581a6987b879712c31d1afea314c8cd1d70d0",
        "id": "4L2u_Ue-3zrP"
      },
      "source": [
        "# <a name=\"feature_12\"></a> A-12. feature_12\n",
        "[Back to INDEX](#index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "020c85170d401c3a2f341363b9c9c226c252c4a0",
        "execution": {
          "iopub.status.busy": "2021-09-22T02:01:15.565268Z",
          "iopub.status.idle": "2021-09-22T02:01:15.565896Z"
        },
        "id": "jGk8pdQt3zrQ"
      },
      "outputs": [],
      "source": [
        "# Call EDA function to explore the time series\n",
        "eda(df, 'feature_12')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "69100adb6f0cab1d357bc5190dce1aefbc18db47",
        "id": "ik_4Adn_3zrQ"
      },
      "source": [
        "# <a name=\"feature_13\"></a> A-13. feature_13\n",
        "[Back to INDEX](#index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "d747f5256683e2730fccdc74b16ad2e269a22f28",
        "execution": {
          "iopub.status.busy": "2021-09-22T02:01:15.569414Z",
          "iopub.status.idle": "2021-09-22T02:01:15.570072Z"
        },
        "id": "UZkI0hd-3zrR"
      },
      "outputs": [],
      "source": [
        "# Call EDA function to explore the time series\n",
        "eda(df, 'feature_13')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "f7656af52f368e092c2835ce95448f575ef3d1e4",
        "id": "lrndSgX03zrR"
      },
      "source": [
        "# <a name=\"feature_14\"></a> A-14. feature_14\n",
        "[Back to INDEX](#index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "b7271e2b9871991f3758ed52b5456c59315bbdfa",
        "execution": {
          "iopub.status.busy": "2021-09-22T02:01:15.570832Z",
          "iopub.status.idle": "2021-09-22T02:01:15.571457Z"
        },
        "id": "3CutFtz63zrR"
      },
      "outputs": [],
      "source": [
        "# Call EDA function to explore the time series\n",
        "eda(df, 'feature_14')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "d55aecc8875ada6cbd2b563cdc5ef754e5a9414f",
        "id": "cco2u8kH3zrS"
      },
      "source": [
        "# <a name=\"feature_15\"></a> A-15. feature_15\n",
        "[Back to INDEX](#index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "df9feceb2864b57db82fb8daabca1c4861dc37f0",
        "execution": {
          "iopub.status.busy": "2021-09-22T02:01:15.572216Z",
          "iopub.status.idle": "2021-09-22T02:01:15.579145Z"
        },
        "id": "2XKLN-YB3zrS"
      },
      "outputs": [],
      "source": [
        "# Call EDA function to explore the time series\n",
        "eda(df, 'feature_15')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "9116f548cd7c67a0f5e2aabd59086dac8afbaaf5",
        "id": "Cs3xxgmj3zrS"
      },
      "source": [
        "# <a name=\"feature_16\"></a> A-16. feature_16\n",
        "[Back to INDEX](#index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "acc91562618a2f0db13c23e52dfbf8ea84c25736",
        "execution": {
          "iopub.status.busy": "2021-09-22T02:01:15.579937Z",
          "iopub.status.idle": "2021-09-22T02:01:15.580555Z"
        },
        "id": "Px2UWSVZ3zrS"
      },
      "outputs": [],
      "source": [
        "# Call EDA function to explore the time series\n",
        "eda(df, 'feature_16')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "6d3d7c61fe14b26e08b8818ca45f584075d03c14",
        "id": "lNuVPXGX3zrT"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "classification-of-time-series-with-lstm-rnn (1).ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}